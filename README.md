# â±ï¸ Time Series Forecasting with LSTM ğŸ§ ğŸ“ˆ
This project demonstrates how to build a Long Short-Term Memory (LSTM) neural network to forecast time series data â€” in this case, the monthly total number of airline passengers ğŸ“Š.

# ğŸ“ Dataset
The dataset used is:

ğŸ—ƒï¸ air-passenger.csv
ğŸ“Œ Column: #Passengers
ğŸ“… Monthly data (1949â€“1960)
ğŸ”¢ Goal: Predict future number of passengers

# ğŸ§° Libraries Used
NumPy & Pandas â€“ Data manipulation

Matplotlib â€“ Plotting ğŸ“‰

Keras â€“ LSTM model building

Sklearn â€“ MinMaxScaler & RMSE

Warnings â€“ To suppress logs

# ğŸ”„ Data Preprocessing
Converted passenger counts to float32

Normalized data using MinMaxScaler

Split into training (67%) and testing (33%)

```python
scaler = MinMaxScaler(feature_range=(0,1))
dataset = scaler.fit_transform(dataset.reshape(-1, 1))
Created sequences using a sliding window (look_back=1):
```
```python
def createDataset(dataset, look_back=1):
    datax, datay = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i+look_back), 0]
        datax.append(a)
        datay.append(dataset[i + look_back, 0])
    return np.array(datax), np.array(datay)
```
# ğŸ§  Model Architecture (LSTM)
1 LSTM layer

1 Dense layer for output

Compiled with mean_squared_error loss and adam optimizer

```python
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
```
ğŸ§ª Trained for 100 epochs with batch size = 1

# ğŸ“ˆ Evaluation & Visualization
Evaluated using Root Mean Squared Error (RMSE) on training and test data

Plotted:

Actual vs predicted values

Predictions for training and testing data

```python
plt.plot(scaler.inverse_transform(dataset))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
```
